{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Scalable solution - ResNet50 Pretrained weights CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section, we focus on implementing a highly scalable solution.\n",
    "Scalability in Data science means that we are well equipped to deal with a large influx of data. How might we approach the situation where we have 10x as much data, or a constant stream of new data. How can we make sure that our model can process this large amount of data as efficiently as possible."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We theorise that for our task, a pretrained deep convolutional neural network model will have best performance. Since we have around 5000 images in our training set, we feel that this may not be enough for to train a powerful deep CNN for ourselves, since there will likely be more parameters than data. To be able to learn these very complex relationships between the MRI images and the classes, we would likely need a large CNN with multiple hiddem layers.\n",
    "\n",
    "It can therefore be concluded that utalising a pretrained model could be a successful way of increasing the depth of our network, only having our small test set of MRI images. \n",
    "\n",
    "ResNet-50 is a 50-layer convolutional neural network (48 convolutional layers, one MaxPool layer, and one average pool layer). We use the fact that in pytorch, we can load a set of weights for the network trained on ImageNet. \n",
    "\"The ImageNet project is a large visual database designed for use in visual object recognition software research. More than 14 million images have been hand-annotated by the project to indicate what objects are pictured.\" [1]\n",
    "Note that we have not actually accessed the ImageNet dataset to confirm if it contains the brain MRI dataset we are using in our project. If ImageNet were to contain a small subset of images which are in our testing dataset, this would invalidate our testing accuracy. We continue anyway since in a real commercial or research setting the dataset we use could not be public and therefore not run the risk of this happening, it would absolutely be something to consider."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"Data/Training\"\n",
    "test_dir = \"Data/Testing\"\n",
    "\n",
    "# Define batch size, image dimensions\n",
    "batch_size = 64\n",
    "img_height = 244\n",
    "img_width = 244\n",
    "\n",
    "# Augmentations and transforms for training set\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(360),\n",
    "    transforms.RandomResizedCrop((img_height, img_width), scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=(0.8, 1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Resize and Normalise for test set\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "dataset = torchvision.datasets.ImageFolder(data_dir, transform=transform_train)\n",
    "testset = torchvision.datasets.ImageFolder(test_dir, transform=transform_test)\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Get class names\n",
    "class_names = dataset.classes"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-04-25T16:37:05.930428Z",
     "iopub.execute_input": "2023-04-25T16:37:05.932375Z",
     "iopub.status.idle": "2023-04-25T16:37:09.853539Z",
     "shell.execute_reply.started": "2023-04-25T16:37:05.932323Z",
     "shell.execute_reply": "2023-04-25T16:37:09.852457Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code defines our augmentations and transforms which we apply to the dataset. We use more transforms such as rotations, cropping, flips and changes to the brightness and contrast on our training dataset so that it helps our model generalise well, and look for import features inside the image rather than unimportant features such as skull shape, angle, head size. We only use basic augmentations on the test set to standardise the image format, therefore our test set accuracy will reflect accuracy on the real images.\n",
    "\n",
    "We use the ImageFolder function to apply these transforms to the datasets. If we were to collect more data in the future, we could process the data with this same function and then concatinate it with the already processed data, removing the need to reprocess all of the data.\n",
    "\n",
    "We create a validation set to keep track of during training, ensuring we are careful not to overfit to the training data. This will also help us set out early stopping conditions which could be important when dealing with a large amount of data with slower training since we can stop training at the optimum time and not waste additional computational resources.\n",
    "\n",
    "We put the data into dataloaders with our specified batch size. Using a specified batch size helps us to manage memory effectively during training, limiting how much memory we are using at once. Batch size can be selected based on this, and stochastic qualities for our optimisation algorithm."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_classes = len(class_names)\n",
    "resnet50.fc = torch.nn.Linear(resnet50.fc.in_features, num_classes)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    resnet50 = resnet50.cuda()\n",
    "    \n",
    "# Check if multiple GPUs are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    resnet50 = nn.DataParallel(resnet50)\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet50.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet50.parameters(), lr=0.0001)\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-25T16:37:09.856435Z",
     "iopub.execute_input": "2023-04-25T16:37:09.857134Z",
     "iopub.status.idle": "2023-04-25T16:37:10.358648Z",
     "shell.execute_reply.started": "2023-04-25T16:37:09.857091Z",
     "shell.execute_reply": "2023-04-25T16:37:10.357392Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": "Using 2 GPUs\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section we look for GPU's in the system. Our model, and CNN's in general, can be greatly sped up with GPU processing.\n",
    "We further this by checking for multiple GPU's, and if available, make it so our data can be processed in parallel using all of our GPU power.\n",
    "Setting our device to the GPU allows us to store our tensors on the GPU during training so we can process them on GPU.\n",
    "\n",
    "Setting a low learning rate on Adam optimiser takes advantage of the pretrained weights of the model such that we only make fine tuning adjustments. A larger learning rate may try to make too big steps to find a good minimum for this deep CNN."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, device, early_stopping_patience=5):\n",
    "    model.train()\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # tqdm progress bar\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        for i, data in enumerate(pbar, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(loss=loss.item(), acc=(torch.sum(preds == labels.data).item() / inputs.size(0)))\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            val_running_loss = 0.0\n",
    "            val_running_corrects = 0\n",
    "\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
    "            val_epoch_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "            print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_acc:.4f}\")\n",
    "            \n",
    "            if val_epoch_loss < best_val_loss:\n",
    "                best_val_loss = val_epoch_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered after {early_stopping_patience} epochs without improvement in validation loss.\")\n",
    "                torch.save(model.state_dict(), \"best_ResNet50_model.pth\")\n",
    "                break\n",
    "    torch.save(model.state_dict(), \"best_ResNet50_model.pth\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 15\n",
    "trained_model = train_model(resnet50, criterion, optimizer, train_loader, val_loader, num_epochs, device, early_stopping_patience=5)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-25T16:37:10.360785Z",
     "iopub.execute_input": "2023-04-25T16:37:10.361336Z",
     "iopub.status.idle": "2023-04-25T16:52:53.643814Z",
     "shell.execute_reply.started": "2023-04-25T16:37:10.361294Z",
     "shell.execute_reply": "2023-04-25T16:52:53.642475Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "text": "Epoch 1/15: 100%|██████████| 72/72 [00:53<00:00,  1.35it/s, acc=0.76, loss=0.776] ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 1/15, Loss: 0.5038, Accuracy: 0.8387\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.2927, Validation Accuracy: 0.9046\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 2/15: 100%|██████████| 72/72 [00:51<00:00,  1.39it/s, acc=0.96, loss=0.0742] ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 2/15, Loss: 0.3047, Accuracy: 0.8941\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.2039, Validation Accuracy: 0.9291\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 3/15: 100%|██████████| 72/72 [00:52<00:00,  1.38it/s, acc=1, loss=0.0614]    ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 3/15, Loss: 0.1445, Accuracy: 0.9470\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.1171, Validation Accuracy: 0.9589\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 4/15: 100%|██████████| 72/72 [00:51<00:00,  1.39it/s, acc=1, loss=0.0282]    ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 4/15, Loss: 0.1211, Accuracy: 0.9569\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.1621, Validation Accuracy: 0.9396\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 5/15: 100%|██████████| 72/72 [00:52<00:00,  1.38it/s, acc=0.96, loss=0.101]  ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 5/15, Loss: 0.0966, Accuracy: 0.9643\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.0985, Validation Accuracy: 0.9659\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 6/15: 100%|██████████| 72/72 [00:51<00:00,  1.39it/s, acc=0.92, loss=0.097]  ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 6/15, Loss: 0.0769, Accuracy: 0.9698\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.1033, Validation Accuracy: 0.9694\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 7/15: 100%|██████████| 72/72 [00:52<00:00,  1.36it/s, acc=0.96, loss=0.106]  ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 7/15, Loss: 0.0812, Accuracy: 0.9731\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.0748, Validation Accuracy: 0.9781\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 8/15: 100%|██████████| 72/72 [00:52<00:00,  1.36it/s, acc=0.92, loss=0.257]  ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 8/15, Loss: 0.0649, Accuracy: 0.9783\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.0995, Validation Accuracy: 0.9650\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 9/15: 100%|██████████| 72/72 [00:51<00:00,  1.40it/s, acc=0.96, loss=0.133]  ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 9/15, Loss: 0.0560, Accuracy: 0.9810\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.0637, Validation Accuracy: 0.9825\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 10/15: 100%|██████████| 72/72 [00:52<00:00,  1.38it/s, acc=1, loss=0.00544]   ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 10/15, Loss: 0.0522, Accuracy: 0.9814\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.1237, Validation Accuracy: 0.9633\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 11/15: 100%|██████████| 72/72 [00:51<00:00,  1.39it/s, acc=0.96, loss=0.105]  ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 11/15, Loss: 0.0509, Accuracy: 0.9847\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.0700, Validation Accuracy: 0.9773\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 12/15: 100%|██████████| 72/72 [00:52<00:00,  1.38it/s, acc=1, loss=0.0077]    ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 12/15, Loss: 0.0473, Accuracy: 0.9831\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.0799, Validation Accuracy: 0.9799\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 13/15: 100%|██████████| 72/72 [00:52<00:00,  1.38it/s, acc=1, loss=0.0158]    ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 13/15, Loss: 0.0468, Accuracy: 0.9836\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.0511, Validation Accuracy: 0.9834\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 14/15: 100%|██████████| 72/72 [00:53<00:00,  1.35it/s, acc=1, loss=0.0153]    ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 14/15, Loss: 0.0330, Accuracy: 0.9891\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.0614, Validation Accuracy: 0.9816\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 15/15: 100%|██████████| 72/72 [00:52<00:00,  1.36it/s, acc=1, loss=0.00215]   ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 15/15, Loss: 0.0692, Accuracy: 0.9766\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Validation Loss: 0.0549, Validation Accuracy: 0.9869\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now implement our training loop. We use a tqdm progress bar to keep track of current progress in each epoch, and ensure training is going to plan. The most notible feature we implement here for scalability is our early_stopping_patience, which keeps track of our best validation loss and if we perform worse than our best validation loss a predefined number of times (here we have set this to 5), we stop training the model. This makes sure that we do not overfit the model, or waste computational resources running a large amount of unneccessary epochs over our data.\n",
    "\n",
    "Furthermore, at the end of training we save our final model. This allows us to load our model parameters in the future to load the model for predictions, or continue training the model at a later date, perhaps with new data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_on_test_set(model, test_loader, device):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "    return true_labels, predicted_labels\n",
    "\n",
    "# Make predictions on the test set\n",
    "true_labels, predicted_labels = predict_on_test_set(trained_model, test_loader, device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-25T16:56:03.217313Z",
     "iopub.execute_input": "2023-04-25T16:56:03.217695Z",
     "iopub.status.idle": "2023-04-25T16:56:10.736471Z",
     "shell.execute_reply.started": "2023-04-25T16:56:03.217662Z",
     "shell.execute_reply": "2023-04-25T16:56:10.735098Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that our model is trained using a defined number of epochs and early stopping conditions, we predict for our test set. The predictions allow us to calculate standard metrics for multiclass classification problems."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-25T16:56:10.824342Z",
     "iopub.execute_input": "2023-04-25T16:56:10.825015Z",
     "iopub.status.idle": "2023-04-25T16:56:10.842305Z",
     "shell.execute_reply.started": "2023-04-25T16:56:10.824944Z",
     "shell.execute_reply": "2023-04-25T16:56:10.840443Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy: 0.9825\nPrecision: 0.9829\nRecall: 0.9825\nF1-score: 0.9825\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that our model performs very well."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To summarise how we have made this implementation focus on scalability:\n",
    "* Preprocessing apply function: We make a function to apply augmentations and transformations to data, such that in the future with more data, we can apply this function to our new data and concatinate it with the already processed data\n",
    "* Batch Dataloaders: We create batches of the data of a defined batch size. This makes sure that we limit the memory usage of the model, allowing us to process as much data as we would like.\n",
    "* Efficient use of multiple GPUs: Using in built pytorch functionality, we look for multiple GPUs and parallise the model to use both at the same time. This could be scaled up for a very large amount of GPUs\n",
    "* Stochastic Gradient Descent: Mini batches are used in training for stochastic gradient updates, meaning we have a faster convergence through using less redundent data and more frequent gradient updates. This will be a large noticable speed upgrade proportional to the amount of data.\n",
    "* Early stopping condition: We stop the model training when we are no longer performing better than our best model, saving computational resources,\n",
    "* Model checkpointing: We save our best model at the end of training which allows us to reload this model at a later date for new predictions or more training in the future.\n",
    "\n",
    "In the future we would like to do more research about how the parallel GPUs work together in this setting. We assume that the built-in parallelism of the pytorch functions is very efficient, but it could be useful to know if there was any additional ways we could have set out our data which would allow even better performance with multiple GPUs enabled."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[1]: Wikipedia contributors. \"ImageNet.\" Wikipedia, The Free Encyclopedia. Wikipedia, The Free Encyclopedia, 27 Mar. 2023. Web. 3 May. 2023."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
